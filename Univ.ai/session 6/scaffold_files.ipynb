{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the  re, and pickle library\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the 'inception.txt' file and read the file contents to `text`\n",
    "# make sure to convert the contents to LOWERCASE using the .lower() string method\n",
    "file_name = \"inception.txt\"\n",
    "\n",
    "# Run the code cell below to get the script of the movie as a string\n",
    "with open(file_name) as f:\n",
    "    text = f.read().lower()   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è∏ Which regular expression can catch all the **words** (and only words) in a string of only lowercase words? (eg. `\"this is a sentence with words and 123\"`)\n",
    "\n",
    "\n",
    "#### A. `'\\w+'`\n",
    "#### B. `'[a-z]+'`\n",
    "#### C. `'[a-z]*'`\n",
    "#### D. `All of the above`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow1) ###\n",
    "\n",
    "# Submit an answer choice as a string below (eg. if you choose option C, put 'C')\n",
    "answer1 = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a list of words from the `text` string\n",
    "word_list = re.findall(r'\\b[a-z]+\\b', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "# stopwords are words of a language that frequently occur in a sentence\n",
    "# e.g 'the', 'and'\n",
    "# Below we provide you a list of stop_words in the English language\n",
    "stop_words = pickle.load(open('stopwords.pkl','rb'))\n",
    "print(stop_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_prune) ###\n",
    "# For our analysis, we need to remove all the stop words from the list of words\n",
    "pruned_list = [word for word in word_list if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_count) ###\n",
    "#Create a dictionary called 'wordcount'\n",
    "# and count the occurrences of unique words in pruned_list\n",
    "\n",
    "wordcount = {}\n",
    "\n",
    "# Run through all the words in pruned_list and update the count of unique words\n",
    "for word in pruned_list:\n",
    "    if word in wordcount:\n",
    "        wordcount[word] +=1\n",
    "    else:\n",
    "        wordcount[word] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cobb', 1033), ('arthur', 349), ('ariadne', 333), ('fischer', 268), ('saito', 248), ('int', 225), ('eames', 220), ('mal', 199), ('looks', 167), ('continuous', 123), ('yusuf', 117), ('cut', 115), ('back', 114), ('day', 103), ('know', 81), ('man', 78), ('ext', 78), ('browning', 77), ('turns', 75), ('room', 74)]\n"
     ]
    }
   ],
   "source": [
    "#Use the sorted() function on the items of `wordcount` to sort from highest count to lowest\n",
    "# and select the top 20 most frequently occuring words\n",
    "\n",
    "wordfrequency = sorted(wordcount.items(), key=lambda x: x[1], reverse=True) [:20]\n",
    "\n",
    "# print the top 20 most frequently occuring words\n",
    "print(wordfrequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each element of 'wordfrequency' is a tuple of the 'word' and its 'frequency'\n",
    "# Seperate the two in two separate lists \n",
    "words = [item[0] for item in wordfrequency]\n",
    "frequency = [item[1] for item in wordfrequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words :Frequency\n",
      "cobb      :**************************************************1033\n",
      "arthur    :**************** 349\n",
      "ariadne   :**************** 333\n",
      "fischer   :************ 268\n",
      "saito     :************ 248\n",
      "int       :********** 225\n",
      "eames     :********** 220\n",
      "mal       :********* 199\n",
      "looks     :******** 167\n",
      "continuous:***** 123\n",
      "yusuf     :***** 117\n",
      "cut       :***** 115\n",
      "back      :***** 114\n",
      "day       :**** 103\n",
      "know      :***  81\n",
      "man       :***  78\n",
      "ext       :***  78\n",
      "browning  :***  77\n",
      "turns     :***  75\n",
      "room      :***  74\n"
     ]
    }
   ],
   "source": [
    "# Run the cell below to get a retro 'histogram' for top 10 words and their frequency\n",
    "print(f'{\"Top words\".ljust(10)}:Frequency')\n",
    "for i in range(20):\n",
    "    ratio = frequency[i]/frequency[0]\n",
    "    print(f'{words[i].ljust(10)}:{int(50*ratio)*\"*\"}{str(frequency[i]).rjust(4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
